> 为什么项目没有选择单一模型，而是同时实现了正则、TF-IDF、BERT 和 GPT-4 四种方案？

不同模型适用于不同场景。正则匹配适用于规则性强、意图明确的指令（如“打电话给张三”），准确率高但泛化性差。TF-IDF和BERT适用于更复杂的自然语言理解。

> model_for_tfidf 函数中如何处理中文分词和停用词？为什么需要这一步？

提及jieba库用于中文分词，并解释分词对于TF-IDF模型的重要性。同时，解释停用词过滤（如cn_stopwords）可以去除对意图识别没有帮助的常见词汇，从而提高模型效果。

> bert 的训练代码中会包含哪些关键步骤？

加载预训练模型 BertForSequenceClassification，定义优化器和损失函数，进行多轮迭代训练。

> 如何使用 FastAPI 将这些模型封装成统一的 RESTful API？

提到 FastAPI 的核心优势，如自动生成接口文档（/docs），以及如何通过 POST 请求接收 request_text 参数，并调用对应的模型函数返回结果。

> 如果BERT模型的推理延迟超过400ms，你会如何优化？

模型剪枝（Pruning）、量化（Quantization）、使用更轻量级的模型版本（如DistilBERT），以及利用GPU硬件加速（代码中model.to(device)已体现）。