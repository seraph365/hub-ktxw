# 实施步骤
- 技术路线（技术预研）， 3天确定：大模型 vs  不用大模型
  - 大模型的技术方案：提示词工程、RAG
  - 非大模型的技术方案：TFIDF、正则表达式、LSTM、BERT
- 数据集 & 评测标准，2-3天搞定： 数据集从哪儿来？ 标注如何定义？
  - 公司数据集采集自己公司其他程序的日志（公司已有的业务）
  - doccano数据集标注（5千条样本）：导入数据集、定义标签、多人标注、导出标注数据

- 编码 、实施、测试和部署 （7-14天搞定）
  - 步骤1: 定义接口的规范（别人怎么调用我的？）
  - 步骤2: 大模型流程（写对应的函数）
- 精度问题：
  - qwen大模型不满足要求？（速度不满足）

# 实施中可能遇到的问题

## 项目实施中可能遇到的问题及解决方案





### 1. 模型性能问题



**问题**

- **准确率未达标**：模型在测试集上准确率低于95%，尤其是在一些**长尾意图**（即样本较少、不常见的意图）上表现不佳。
- **模型泛化能力差**：模型对未在训练集中出现过的**新说法、同义句或口语化表达**的识别能力弱。
- **实时性不达标**：模型推理延迟超过400毫秒，无法满足车载系统的即时响应需求。

**解决方案**

- **数据增强**：通过**同义词替换、近义句重写、添加口语化表达**等方式扩充训练数据。利用**回译**（Back-translation）技术将文本翻译成另一种语言再译回，生成更多样的语料。
- **模型优化与微调**：
  - **非大模型方案**：如果使用BERT等模型，可以尝试使用**蒸馏技术**（如将BERT模型蒸馏成更轻量级的DistilBERT），或使用**量化**（Quantization）技术减小模型大小，从而降低推理延迟。
  - **大模型方案**：如果选择大模型，可以探索**更轻量级的开源模型**（如Llama-3的8B或更小版本），或使用**LoRA/QLoRA**等微调技术，在少量数据上微调大模型，使其专注于特定领域，同时保持较小的模型体积。
- **优化推理部署**：使用**ONNX Runtime、TensorRT**等高性能推理引擎进行模型部署，利用硬件加速（如GPU）进一步降低延迟。

------



### 2. 数据相关问题



**问题**

- **数据不平衡**：某些高频意图（如“导航”）的样本量远超低频意图（如“故障报修”），导致模型过度学习高频意图，而忽略低频意图。
- **标注质量不一致**：多人标注时，对意图的定义理解不一，导致部分数据标注错误或模糊。
- **数据收集困难**：高质量、覆盖全面真实场景的口语化数据难以获取。

**解决方案**

- **数据平衡**：
  - **过采样**：对低频意图样本进行复制或使用数据增强技术生成更多样本。
  - **欠采样**：对高频意图样本进行随机删除，以减少其在训练集中的占比。
- **优化标注流程**：
  - **制定详细的标注规范**：明确每个意图的定义、边界和示例，消除歧义。
  - **交叉审核机制**：引入多人交叉审核，确保每一条数据都经过至少两人确认，提高标注质量。
  - **利用主动学习**：模型训练初期，识别出置信度较低或模型易混淆的样本，优先进行人工标注，以更高效地提升模型性能。
- **多渠道数据收集**：除了公司内部日志，可以考虑**众包**或与第三方数据提供商合作，获取更广泛、更具多样性的语料。

------



### 3. 技术选型与实施问题



**问题**

- **大模型方案挑战**：
  - **成本高昂**：大模型API调用或本地部署需要大量的计算资源，成本难以控制。
  - **速度瓶颈**：尽管大模型能力强大，但其巨大的参数量导致推理延迟较高，可能无法满足400毫秒的延迟要求。
- **非大模型方案挑战**：
  - **能力上限**：基于BERT等模型在泛化能力和处理复杂长句方面的表现可能不如大模型，尤其是在面对全新的意图或表述时。
- **部署环境复杂**：将模型封装成API服务并部署到生产环境（如车载边缘设备或云服务器）时，可能会遇到兼容性、资源限制等问题。

**解决方案**

- **技术路线混合方案**：
  - **非大模型作为主模型**：使用微调后的BERT或更轻量级的模型作为核心意图识别模型，以满足低延迟需求。
  - **大模型作为兜底**：当主模型对用户输入置信度过低或无法识别时，将请求转发给大模型API作为补充，处理长尾或未知意图。
