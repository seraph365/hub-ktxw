1. 问题理解

目标：精准把握用户的查询意图，将简短、模糊的用户问题转化为系统能够有效处理的检索 query。

实现流程：

查询接收：系统接收用户的原始问题，例如：“高企认有什么条件？”

查询清洗与归一化：

去除无意义符号、纠正错别字（如“高企认” -> “高企认定”）。

统一表述，如将“PPT”归一化为“ PowerPoint”。

意图识别与扩展：

关键词提取：使用TF-IDF、TextRank或基于深度学习的方法从问题中提取核心关键词（“高企认定”，“条件”）。

同义词扩展：利用同义词词林或领域知识图谱，扩展查询词。例如，将“条件”扩展为“要求”、“标准”、“资质”。

语义理解：使用轻量级模型（如BERT）对查询进行语义编码，理解其深层意图，避免单纯的字面匹配。

查询重写：将简短问题重写为更正式、更可能匹配知识库文档的语句。例如，原问题可重写为：“申请高新技术企业认定需要满足哪些基本条件和要求？”

面临的挑战：

用户提问是短文本且模糊：口语化、缩写、表述不全。

与知识库长文本的关联难：如何让短查询匹配上长文档中的关键段落。

用词不规范：用户用语与官方文件术语存在差异。

解决方案：

构建领域词典：收录“高企”、“专精特新”等行业黑话、缩写与官方术语的映射关系。

采用Embedding模型：使用句子向量模型（如BGE）将问题和知识库片段都转换为向量，在向量空间中进行语义相似度计算，而非字面匹配，有效解决表述差异问题。

引入查询分类：先判断问题属于哪个领域或部门，缩小检索范围，提升精度。

2. 知识检索

目标：从多源、异构的知识库中，精准、快速地找出与优化后查询最相关的文本片段。

实现流程：

知识库预处理：

解析：使用PyMuPDF、python-docx、Apache Tika等工具解析来自PDF、PPT、Word、Excel、网页（HTML）甚至数据库（如Neo4j导出）的结构化/非结构化文档，提取纯文本和元数据。

分块：将长文档按固定大小（如512 tokens）且有重叠（如50 tokens）的方式进行分割，形成更小的文本块。这是平衡检索精度和上下文完整性的关键。

向量化：使用Embedding模型将每个文本块转换为高维向量。

存储：将向量、文本块原文及元数据存入向量数据库。

在线检索：

将步骤1优化后的查询，通过相同的Embedding模型转换为向量。

在向量数据库中进行相似度搜索，计算查询向量与所有文本块向量的相似度，返回Top-K（如Top-5）最相关的文本块及其元数据。

面临的挑战：

用户提问表达多样：同一问题有多种问法。

知识来源格式多样：PDF、PPT、Neo4j等不同格式需要统一处理。

检索精度与召回率的平衡：既要找到所有相关文档（高召回率），又要保证找到的都是相关的（高精度）。

解决方案：

统一解析引擎：采用Unstructured.io等库提供统一的接口来处理上百种文件格式。

混合检索：结合语义检索和关键词检索。语义检索保证召回率，关键词检索保证精度，两者结果融合后排序，效果最佳。

重排序：使用更精细的交叉编码器模型对Top-K的检索结果进行再次精排，进一步提升排名最前结果的相关性。

3. 答案生成 

目标：将检索到的最相关知识片段与用户问题结合，生成一个准确、自然、且可溯源的最终答案。

实现流程：

（1）提示词工程：

构建一个清晰的Prompt模板，将检索到的上下文和用户问题组装起来。

（2）大语言模型调用：

将组装好的Prompt发送给LLM（如DeepSeek, GPT-4）。

设置生成参数。

（3）后处理与溯源：

提取LLM返回的答案文本。

将Prompt中使用的文本块的元数据格式化，附在答案末尾，实现答案溯源。

面临的挑战：

幻觉：LLM可能忽略提供的上下文，根据自己的知识编造答案。

上下文整合：如何将多个可能来自不同文档的检索片段有机地整合成一个连贯的答案。

拒答：当检索到的知识确实不包含答案时，需要LLM能够诚实地说“不知道”。

解决方案：

强化指令：在Prompt中使用强硬指令来抑制幻觉。

引用校验：设计流程，让LLM在生成答案的每个关键点时都引用对应的文本块编号，后续再替换为真实出处。

设置置信度阈值：如果检索到的所有文本块与问题的相似度都低于某个阈值，则直接触发拒答流程，不调用LLM。
