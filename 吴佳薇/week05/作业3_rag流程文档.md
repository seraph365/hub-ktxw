一、RAG 核心流程
1 知识库与文档管理阶段
1.1知识库创建

用户通过 /v1/knowledge_base POST 接口创建知识库

系统在关系型数据库（SQLite/MySQL）中记录知识库元信息（ID、名称、分类等）

返回知识库唯一标识符 knowledge_id

1.2文档上传与处理

用户通过 /v1/document POST 接口上传文档（如 PDF、Word）

系统执行以下处理流程：
a. 将文档元信息存入数据库
b. 将文件保存到服务器本地存储
c. 启动后台任务解析文档内容

1.3文档内容解析与向量化

系统使用 pdfplumber 等工具提取文档文本内容

对文档进行分块处理（按页面和重叠块）

使用 Embedding 模型将每个文本块转换为向量表示

将文本块内容及其向量存储到 Elasticsearch 中

2 问答检索阶段
2.1用户查询处理

用户通过 /chat POST 接口提交问题和指定知识库

系统接收查询并准备处理

2.2混合检索策略

关键词检索：使用 Elasticsearch 的 BM25 算法进行全文检索

向量检索：将用户查询转换为向量，使用 ES 的 k-NN 搜索查找相似内容

结果融合：采用倒数排名融合（RRF）算法合并两种检索方法的结果

2.3结果精排序

如果配置启用，使用 Rerank 模型对检索结果进行精排序

确保最相关的内容排在前面

3 答案生成阶段
3.1提示工程

将检索到的相关文档块与用户问题组合成提示模板

提示模板包含当前时间、相关文档内容和用户问题

3.2LLM 交互

将组装好的提示发送给大语言模型（如 GPT）

请求模型基于提供的上下文生成答案

3.3响应返回

接收模型生成的回答

将回答返回给用户完成问答循环

二、技术架构详解
1.1 数据存储层
关系型数据库 (SQLite/MySQL)

存储知识库和文档的元数据信息

管理知识库-文档的层级关系

向量搜索引擎 (Elasticsearch)

document_meta 索引：存储文档元信息和摘要

chunk_info 索引：存储文本块内容、元数据和向量嵌入

支持全文检索和向量相似度搜索

1.2 AI 模型层
Embedding 模型

将文本转换为高维向量表示

支持中文文本处理（如 BGE 系列模型）

Rerank 模型

对检索结果进行精排序

提高最终结果的相关性

大语言模型 (LLM)

通过 API 调用（如 OpenAI GPT）

根据检索到的上下文生成自然语言回答

1.3 业务逻辑层
文档处理管道

文件上传、解析、分块和向量化

支持多种文件类型（PDF、Word 等）

检索融合算法

结合关键词和向量检索的优势

使用 RRF 算法实现结果融合

问答生成引擎

提示工程和上下文组装

LLM 交互和响应处理

三、API 接口设计
系统提供以下主要 API 端点：

1 知识库管理

POST /v1/knowledge_base - 创建知识库

GET /v1/knowledge_base - 查询知识库

DELETE /v1/knowledge_base - 删除知识库

2 文档管理

POST /v1/document - 上传文档

GET /v1/document - 查询文档

DELETE /v1/document - 删除文档

3 AI 能力

POST /v1/embedding - 文本向量化服务

POST /v1/rerank - 重排序服务

POST /chat - 知识库问答服务

四、关键特性
多知识库支持：可创建和管理多个独立的知识库

混合检索：结合关键词和向量检索，提高检索准确性

后台处理：文档解析和向量化在后台异步执行，不阻塞请求

可扩展架构：支持多种文件类型和 AI 模型

完整测试覆盖：提供单元测试和集成测试确保系统稳定性

五、部署与配置
系统通过 config.yaml 文件进行配置，支持：

数据库连接配置（SQLite/MySQL）

Elasticsearch 连接参数

AI 模型选择和路径配置

RAG 参数调整（分块大小、重叠度等）

LLM API 密钥和端点配置
