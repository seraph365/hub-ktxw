# 深度学习调参

[toc]

## 1.调参经验

- 用ReLU作为激活函数
- 分类时用交叉熵(CE, BCE)作为损失函数
- SDG+mini-batch
- 每个epoch训练时重新随机排序训练样本
- 数据预处理（标准归一化）
- 动态学习率（越来越小）
- 用L1或L2正则化（跳过前几轮）
- 逐层归一化
- dropout
- 数据增强



## 2.超参数

- 层数
- 每层神经元个数
- 激活函数
- 学习率（以及动态调整算法）
- 正则化系数



## 3.优化方法

- 网格搜索
- 随机搜索
- 贝叶斯优化
- 动态资源分配
- 神经网络搜索