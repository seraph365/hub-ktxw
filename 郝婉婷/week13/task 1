## MCP服务
from fastapi import FastAPI
import openai
import os

app = FastAPI()
openai.api_key = os.getenv("OPENAI_API_KEY", "your-api-key")

@app.post("/chat")
async def chat(prompt: str):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return {"response": response.choices[0].message.content}
    except Exception as e:
        return {"error": str(e)}

@app.get("/health")
async def health():
    return {"status": "ok"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)

## fastapi后端
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import httpx

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"])

MCP_URL = "http://localhost:8001"

@app.post("/api/chat")
async def chat(message: str):
    async with httpx.AsyncClient() as client:
        response = await client.post(f"{MCP_URL}/chat", json={"prompt": message})
        return response.json()

@app.get("/api/health")
async def health():
    async with httpx.AsyncClient() as client:
        mcp_health = await client.get(f"{MCP_URL}/health")
        return {"backend": "ok", "mcp": mcp_health.json()}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
