## **政企问答项目 RAG 实现流程文档**

### **1. 概述**

该系统通过结合外部知识库的精准检索和大语言模型（LLM）的强大生成能力，旨在回答用户关于政策、企业规章、操作手册等领域的专业问题，同时有效缓解LLM的幻觉、时效性和数据安全等问题。

### **2. 核心流程**

整个RAG流程可划分为“知识库准备（离线）”和“问答处理（在线）”两大阶段。

#### **阶段一：知识库准备（离线处理）**

此阶段将原始文档处理成系统可快速检索的结构化格式，通常在数据更新时执行。

1.  **文档解析与加载**
    *   **输入**： 各种格式的原始文档（PDF, Word, Excel, PPT, HTML, 数据库等）。
    *   **处理**： 使用文档解析库（如 `Unstructured`, `PaddleOCR` for 扫描件）将不同格式的文件统一转换为纯文本。同时提取元数据（如文件名、标题、页码、更新时间等）。

2.  **文本切分**
    *   **处理**： 使用文本分割器将长文本切分为更小的、语义完整的“文本块”。
    *   **方法**： 通常采用**递归字符分割**，辅以重叠窗口（Overlap）来保持上下文的连贯性。对于结构化内容（如Markdown/HTML），会采用基于标题的分割以保持语义完整性。
    *   **输出**： 一组文本块及其关联的元数据。

3.  **向量化与索引构建**
    *   **向量化**： 使用嵌入模型（如 `Qwen-Embedding`, `BGE`）将每个文本块转换为一个高维向量（Embedding）。
    *   **索引构建**： 将所有文本块的向量存入向量数据库（如 `FAISS`, `Chroma`, `Milvus`）并构建索引，以便后续进行高效的相似性搜索。同时，原始文本和元数据也会被存储起来（通常在一个键值数据库中）。

#### **阶段二：问答处理（在线处理）**

此阶段在用户提问时实时触发，是RAG的核心响应循环。

1.  **用户提问**
    *   **输入**： 用户输入自然语言问题。

2.  **意图识别与查询处理**
    *   **意图识别**： 判断用户问题是否在系统知识范围内。例如，通过提问向量与预设问题类别的向量进行相似度比较，或使用小型分类器/Prompt进行判断。
    *   **查询处理/改写**： 对原始查询进行优化，可能包括：
        *   **查询改写**： 使用LLM将口语化、模糊的提问改写为更规范、更利于检索的语句。
        *   **关键词扩展**： 提取或生成同义词、近义词，以扩大检索范围。
        *   **问题路由**： 判断问题应使用向量检索还是全文检索（如用于精确匹配术语）。

3.  **知识检索**
    *   **检索**： 将处理后的查询语句同样转换为向量，并在向量数据库中进行相似度搜索（如K近邻算法），找出最相关的K个文本块。
    *   **多路召回与重排序**：
        *   **多路召回**： 可能同时使用**向量检索**和**关键词检索**（如BM25），综合两者的结果以获得更全面和准确的结果。
        *   **重排序**： 使用更精细的交叉编码器模型对召回的Top-K结果进行重新打分和排序，过滤掉相关性较低的内容，解决“Lost in the Middle”问题，提升TOP结果的精度。

4.  **提示工程与答案生成**
    *   **提示构建**： 将检索到的最相关的N个文本块作为“上下文”，与用户的原始“问题”一起，填充到预先设计好的Prompt模板中。
    *   **模板示例**：
        ```text
        ''现在的时间是{#TIME#}。你是一个专家，你擅长回答用户提问，帮我结合给定的资料，回答下面的问题。
        如果问题无法从资料中获得，或无法从资料中进行回答，请回答无法回答。如果提问不符合逻辑，请回答无法回答。
        如果问题可以从资料中获得，则请逐步回答。

        资料：
        {#RELATED_DOCUMENT#}


        问题：{#QUESTION#}
        '''
        ```
      **答案生成**： 将构建好的Prompt发送给线上大语言模型（如 `GPT-4`, `Qwen`, `Llama`），LLM根据提供的上下文生成最终答案。

5.  **响应与引用展示**
    *   **输出**： 将LLM生成的答案返回给用户。
    *   **可解释性**： 同时附上答案所引用的源文本块及其元信息（如来源文件名、页码），增强回答的可信度和可追溯性。

### **3. 关键技术组件**

*   **文档解析器**： `Unstructured IO`, `PaddleOCR`
*   **文本分割器**： `RecursiveCharacterTextSplitter`, `SemanticChunker`
*   **嵌入模型**： `BGE-large-zh`, `Qwen-Embedding`, `text2vec`
*   **向量数据库**： `FAISS`, `Chroma`, `Weaviate`, `Milvus`
*   **大语言模型**： `GPT-4`, `Qwen-Max`, `Llama 3`, `ChatGLM`
*   **重排序模型**： `bge-reranker`, `Qwen-Reranker`

### **4. 总结**

该RAG流程通过将外部知识库与LLM能力相结合，为政企场景提供了一个准确、可靠且可追溯的智能问答解决方案。离线阶段专注于知识的结构化处理，在线阶段则高效地完成了从用户问题到精准答案的转换。持续的优化点通常在于检索精度（chunk策略、重排序）和提示工程（Prompt Design）上。
