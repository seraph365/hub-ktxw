---
title: RNN、LSTM、GRU、Transformer的优缺点
markmap:
  colorFreezeLevel: 2
---

## RNN (循环神经网络)

### 优点

- 结构简单，参数少
- 能处理变长序列数据
- 可捕捉时序依赖关系

### 缺点

- 存在梯度消失/爆炸问题
- 难以捕捉长距离依赖
- 无法并行计算，效率低

## LSTM (长短期记忆网络)

### 优点

- 通过门控机制有效缓解梯度消失问题
- 能学习长距离依赖关系
- 有选择性地记忆和遗忘信息

### 缺点

- 结构复杂，参数量大
- 计算成本高
- 仍无法并行处理

## GRU (门控循环单元)

### 优点

- 简化了LSTM结构，只有重置门和更新门
- 参数更少，训练更快
- 性能通常与LSTM相当

### 缺点

- 表达能力可能略逊于LSTM
- 同样无法并行计算
- 对某些需要精细记忆控制的任务不如LSTM

## Transformer

### 优点

- 基于自注意力机制，可并行计算
- 能有效捕捉全局依赖关系，不受距离限制
- 多头注意力可关注不同特征
- 在各种NLP任务中表现卓越

### 缺点

- 计算复杂度随序列长度呈平方增长
- 需要额外的位置编码
- 参数量大，需要大量数据训练
- 计算资源要求高
