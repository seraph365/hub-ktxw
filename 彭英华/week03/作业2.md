# 四种模型的对比


| 模型                | 优点                                                                 | 缺点                                                                 | 适用场景                                                                 |
| :------------------: | :-------------------------------------------------------------------: | :-------------------------------------------------------------------: | :-----------------------------------------------------------------------: |
| **正则表达式**      | 模型较为简单，不需要训练数据集和标注数据。计算成本低，可解释性强，如果匹配到对应词识别准确率很高                                             | 泛化能力差，可能因为匹配规则不包含某些词而错判。不能处理复杂的语义，维护成本高，需要不断的更新匹配规则。扩展能力差，每个任务的规则只能适用于这一任务，不能扩展到其他任务                                         | 简单、固定的任务，通过匹配关键词来进行识别                                                         |
| **TF-IDF + SVM**    | 泛化能力强于正则匹配，可以识别出一些未预定义的规则，计算和训练速度相比深度学习更快，可解释性强，可以通过查看TF-IDF特征权重和SVM向量了解哪些词对分类贡献大                                             | 识别的准确性很大程度上依赖于特征工程，需要不断调参。无法捕捉语义和上下文，特征维度高，每个文本的特征向量极其稀疏，测试集不能处理训练集中未出现的词                                             | 数据集规模较小，并且对训练时间和计算成本有所约束的任务                                                |
| **BERT (微调)**     | 性能远超传统的机器学习，能充分理解词序，上下文关系和复杂的语义，泛化能力强，即使下游任务的标注数据不多也可以取得很好的效果，不需要手动设计特征                                         | 计算成本高，需要大量的gpu和cpu资源，速度远慢于传统机器学习方法，需要很多高质量标注的数据集，可解释性差，模型的决策过程难以解释，模型参数过多                                             | 对准确率要求高的复杂任务，拥有足够多的计算资源和数据                                                 |
| **大模型 (提示工程)** | 泛化能力强，不需要训练数据，通用性强，可以通过设计不同的提示词完成不同的任务，能够处理复杂的指令和语境                                         | 成本高，如果本地部署模型，则需要大量的显存和内存资源。延迟高，调用api受限于网络通信。可控性和可靠性差，模型往往会输出多余的内容，受限于训练日期可能存在幻觉，有些隐私数据不能发送给第三方api                                     | 缺乏标注数据，快速进行验证，复杂多变的分类任务                                                |
